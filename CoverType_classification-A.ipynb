{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/JohnMichaelCourville/Forest-Cover-Type-Classification/blob/main/CoverType_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kmO-G07zIIIe"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import  InputLayer\n",
    "from tensorflow.keras.layers import  Dense\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data and get value counts and percentages of each of the seven classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yi2B714hIVvS",
    "outputId": "cd37e5e6-0201-42f1-f356-4ef2c140d616",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts: \n",
      "\n",
      "2    283301\n",
      "1    211840\n",
      "3     35754\n",
      "7     20510\n",
      "6     17367\n",
      "5      9493\n",
      "4      2747\n",
      "Name: class, dtype: int64\n",
      "\n",
      "\n",
      "Percentages\n",
      "\n",
      "      class\n",
      "2  0.487599\n",
      "1  0.364605\n",
      "3  0.061537\n",
      "7  0.035300\n",
      "6  0.029891\n",
      "5  0.016339\n",
      "4  0.004728\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('cover_data.csv')\n",
    "\n",
    "print(\"Value counts: \\n\")\n",
    "print(data['class'].value_counts());\n",
    "print(\"\\n\")\n",
    "print('Percentages\\n')\n",
    "percentages = data['class'].value_counts()\n",
    "perc = percentages.to_frame()\n",
    "\n",
    "# print(percentages)\n",
    "perc['class'] = perc['class']/len(data)\n",
    "print(perc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since class 1 and 2 make up over 80% of the sample, we will run some models using the original sample and some using a sample with a large portion of 1 and 2 removed. \n",
    "\n",
    "Below we remove the samples with 1 and 2 classifcations from the data and then remove a large portion of the sample from each set then create the new \"data_evened\" data frame. \n",
    "\n",
    "Classification 1 and 2 only account for ~16% of the new evened data frame.  We will run the models on this data frame at the end to compare with the results of running models on the entire data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yi2B714hIVvS",
    "outputId": "cd37e5e6-0201-42f1-f356-4ef2c140d616",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts: \n",
      "\n",
      "2    63301\n",
      "3    35754\n",
      "1    31840\n",
      "7    20510\n",
      "6    17367\n",
      "5     9493\n",
      "4     2747\n",
      "Name: class, dtype: int64\n",
      "\n",
      "\n",
      "Percentages\n",
      "\n",
      "      class\n",
      "2  0.108950\n",
      "3  0.061537\n",
      "1  0.054801\n",
      "7  0.035300\n",
      "6  0.029891\n",
      "5  0.016339\n",
      "4  0.004728\n"
     ]
    }
   ],
   "source": [
    "data_1 = data.loc[data['class']==1]\n",
    "data_2 = data.loc[data['class']==2]\n",
    "\n",
    "data_1 = data_1.iloc[:-180000,:]\n",
    "data_2 = data_2.iloc[:-220000,:]\n",
    "\n",
    "data_evened = data.loc[(data['class']!= 1)&(data['class']!= 2)]\n",
    "data_evened['class'].value_counts()\n",
    "\n",
    "data_evened = pd.concat([data_evened, data_1, data_2])\n",
    "\n",
    "print(\"Value counts: \\n\")\n",
    "print(data_evened['class'].value_counts());\n",
    "print(\"\\n\")\n",
    "print('Percentages\\n')\n",
    "percentages = data_evened['class'].value_counts()\n",
    "perc = percentages.to_frame()\n",
    "\n",
    "# print(percentages)\n",
    "perc['class'] = perc['class']/len(data)\n",
    "print(perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating feature and label set using the entire data set and standardizing the features set using z-score standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C9kRjzPUKO7Q",
    "outputId": "e6b3db9f-8326-4874-8809-51ca1528dc12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
      "0            2596      51      3                               258   \n",
      "1            2590      56      2                               212   \n",
      "2            2804     139      9                               268   \n",
      "3            2785     155     18                               242   \n",
      "4            2595      45      2                               153   \n",
      "...           ...     ...    ...                               ...   \n",
      "581007       2396     153     20                                85   \n",
      "581008       2391     152     19                                67   \n",
      "581009       2386     159     17                                60   \n",
      "581010       2384     170     15                                60   \n",
      "581011       2383     165     13                                60   \n",
      "\n",
      "        Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
      "0                                    0                              510   \n",
      "1                                   -6                              390   \n",
      "2                                   65                             3180   \n",
      "3                                  118                             3090   \n",
      "4                                   -1                              391   \n",
      "...                                ...                              ...   \n",
      "581007                              17                              108   \n",
      "581008                              12                               95   \n",
      "581009                               7                               90   \n",
      "581010                               5                               90   \n",
      "581011                               4                               67   \n",
      "\n",
      "        Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
      "0                 221             232            148   \n",
      "1                 220             235            151   \n",
      "2                 234             238            135   \n",
      "3                 238             238            122   \n",
      "4                 220             234            150   \n",
      "...               ...             ...            ...   \n",
      "581007            240             237            118   \n",
      "581008            240             237            119   \n",
      "581009            236             241            130   \n",
      "581010            230             245            143   \n",
      "581011            231             244            141   \n",
      "\n",
      "        Horizontal_Distance_To_Fire_Points  ...  Soil_Type31  Soil_Type32  \\\n",
      "0                                     6279  ...            0            0   \n",
      "1                                     6225  ...            0            0   \n",
      "2                                     6121  ...            0            0   \n",
      "3                                     6211  ...            0            0   \n",
      "4                                     6172  ...            0            0   \n",
      "...                                    ...  ...          ...          ...   \n",
      "581007                                 837  ...            0            0   \n",
      "581008                                 845  ...            0            0   \n",
      "581009                                 854  ...            0            0   \n",
      "581010                                 864  ...            0            0   \n",
      "581011                                 875  ...            0            0   \n",
      "\n",
      "        Soil_Type33  Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  \\\n",
      "0                 0            0            0            0            0   \n",
      "1                 0            0            0            0            0   \n",
      "2                 0            0            0            0            0   \n",
      "3                 0            0            0            0            0   \n",
      "4                 0            0            0            0            0   \n",
      "...             ...          ...          ...          ...          ...   \n",
      "581007            0            0            0            0            0   \n",
      "581008            0            0            0            0            0   \n",
      "581009            0            0            0            0            0   \n",
      "581010            0            0            0            0            0   \n",
      "581011            0            0            0            0            0   \n",
      "\n",
      "        Soil_Type38  Soil_Type39  Soil_Type40  \n",
      "0                 0            0            0  \n",
      "1                 0            0            0  \n",
      "2                 0            0            0  \n",
      "3                 0            0            0  \n",
      "4                 0            0            0  \n",
      "...             ...          ...          ...  \n",
      "581007            0            0            0  \n",
      "581008            0            0            0  \n",
      "581009            0            0            0  \n",
      "581010            0            0            0  \n",
      "581011            0            0            0  \n",
      "\n",
      "[581012 rows x 54 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#remove classification column from feature set\n",
    "X = data.loc[:,:'Soil_Type40']\n",
    "print(X)\n",
    "#create labels set of classification column\n",
    "y = data.loc[:,'class']\n",
    "\n",
    "#convert labels to one-hot endoded labels in order to use categoricalcrossentropy\n",
    "\n",
    "#Z score standardization\n",
    "ct = StandardScaler()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Random Forest Classification produced impressive results.  Because of this, we will run it again using 5 fold stratification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         0\n",
      "           1       0.97      0.93      0.95     63552\n",
      "           2       0.95      0.97      0.96     84991\n",
      "           3       0.95      0.94      0.95     10726\n",
      "           4       0.93      0.79      0.86       824\n",
      "           5       0.95      0.70      0.81      2848\n",
      "           6       0.95      0.86      0.90      5210\n",
      "           7       0.98      0.94      0.96      6153\n",
      "\n",
      "   micro avg       0.96      0.95      0.95    174304\n",
      "   macro avg       0.96      0.89      0.92    174304\n",
      "weighted avg       0.96      0.95      0.95    174304\n",
      " samples avg       0.96      0.95      0.95    174304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, stratify = y)\n",
    "\n",
    "# one-hot endoding the labels\n",
    "y_train = tf.keras.utils.to_categorical(y_train, dtype = 'int64')\n",
    "y_test = tf.keras.utils.to_categorical(y_test, dtype = 'int64')\n",
    "x_train.head()\n",
    "\n",
    "#Z score standardization\n",
    "ct = StandardScaler()\n",
    "\n",
    "x_train = ct.fit_transform(x_train)\n",
    "x_test = ct.transform(x_test)\n",
    "#print(x_train)\n",
    "\n",
    "model_forest = RandomForestClassifier()\n",
    "model_forest.fit(x_train, y_train)\n",
    "model_forest.score(x_test, y_test)\n",
    "\n",
    "y_predict = model_forest.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_predict, zero_division = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the random forrest with the 5 fold stratification produced results that were very poor in comparison. At the moment, I am unsure as to why the performance was so much worst. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iqMueJCNjMDK",
    "outputId": "d0b6dc89-ab39-47d4-ea1a-821abfd31857",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y estimate: (116203, 8)\n",
      "y estimate: (116203,)\n",
      "Report: [     2      3      4 ... 581008 581010 581011]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.98      0.97     42368\n",
      "           2       0.97      0.97      0.97     56660\n",
      "           3       0.97      0.96      0.96      7151\n",
      "           4       0.92      0.84      0.88       550\n",
      "           5       0.91      0.87      0.89      1899\n",
      "           6       0.94      0.94      0.94      3473\n",
      "           7       0.99      0.91      0.95      4102\n",
      "\n",
      "    accuracy                           0.97    116203\n",
      "   macro avg       0.95      0.92      0.94    116203\n",
      "weighted avg       0.97      0.97      0.97    116203\n",
      "\n",
      "y estimate: (116203, 8)\n",
      "y estimate: (116203,)\n",
      "Report: [     0      1      2 ... 581008 581009 581010]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.98      0.97     42368\n",
      "           2       0.98      0.97      0.97     56660\n",
      "           3       0.97      0.96      0.97      7151\n",
      "           4       0.90      0.85      0.87       550\n",
      "           5       0.91      0.87      0.89      1899\n",
      "           6       0.94      0.95      0.94      3473\n",
      "           7       0.99      0.91      0.95      4102\n",
      "\n",
      "    accuracy                           0.97    116203\n",
      "   macro avg       0.95      0.93      0.94    116203\n",
      "weighted avg       0.97      0.97      0.97    116203\n",
      "\n",
      "y estimate: (116202, 8)\n",
      "y estimate: (116202,)\n",
      "Report: [     0      1      3 ... 581008 581009 581011]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.98      0.97     42368\n",
      "           2       0.98      0.97      0.97     56660\n",
      "           3       0.97      0.96      0.97      7151\n",
      "           4       0.93      0.89      0.91       549\n",
      "           5       0.93      0.87      0.90      1899\n",
      "           6       0.93      0.94      0.94      3473\n",
      "           7       0.99      0.90      0.94      4102\n",
      "\n",
      "    accuracy                           0.97    116202\n",
      "   macro avg       0.96      0.93      0.94    116202\n",
      "weighted avg       0.97      0.97      0.97    116202\n",
      "\n",
      "y estimate: (116202, 8)\n",
      "y estimate: (116202,)\n",
      "Report: [     0      1      2 ... 581009 581010 581011]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.98      0.97     42368\n",
      "           2       0.98      0.97      0.97     56661\n",
      "           3       0.97      0.96      0.97      7150\n",
      "           4       0.91      0.84      0.88       549\n",
      "           5       0.91      0.87      0.89      1898\n",
      "           6       0.94      0.94      0.94      3474\n",
      "           7       0.99      0.90      0.95      4102\n",
      "\n",
      "    accuracy                           0.97    116202\n",
      "   macro avg       0.95      0.92      0.94    116202\n",
      "weighted avg       0.97      0.97      0.97    116202\n",
      "\n",
      "y estimate: (116202, 8)\n",
      "y estimate: (116202,)\n",
      "Report: [     0      1      2 ... 581009 581010 581011]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.98      0.96     42368\n",
      "           2       0.98      0.97      0.97     56660\n",
      "           3       0.97      0.96      0.97      7151\n",
      "           4       0.91      0.85      0.88       549\n",
      "           5       0.91      0.87      0.89      1898\n",
      "           6       0.94      0.95      0.94      3474\n",
      "           7       0.99      0.90      0.95      4102\n",
      "\n",
      "    accuracy                           0.97    116202\n",
      "   macro avg       0.95      0.92      0.94    116202\n",
      "weighted avg       0.97      0.97      0.97    116202\n",
      "\n",
      "List of possible accuracy: [0.9542524719671609, 0.9558789359999311, 0.9564895612812172, 0.9556462023028863, 0.9548114490284161]\n",
      "\n",
      "Maximum Accuracy That can be obtained from this model is: 95.64895612812172 %\n",
      "\n",
      "Minimum Accuracy: 95.42524719671609 %\n",
      "\n",
      "Overall Accuracy: 95.54157241159224 %\n",
      "\n",
      "Standard Deviation is: 0.0008858774809053015\n"
     ]
    }
   ],
   "source": [
    "model_forest = RandomForestClassifier()\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "lst_accu_stratified = []\n",
    "X_array = X.to_numpy()\n",
    "\n",
    "# X_array.type\n",
    "\n",
    "for train_index, test_index in skf.split(X_array, y):\n",
    "    x_train_fold, x_test_fold = X_array[train_index], X_array[test_index]\n",
    "    y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "    model_forest.fit(ct.fit_transform(x_train_fold), y_train_fold)\n",
    "    lst_accu_stratified.append(model_forest.score(ct.transform(x_test_fold), y_test_fold))\n",
    "    y_estimate = model.predict(ct.transform(x_test_fold))\n",
    "    print('y estimate: ' + str(y_estimate.shape))\n",
    "    y_estimate = np.argmax(y_estimate, axis = 1)\n",
    "    print('y estimate: ' + str(y_estimate.shape))\n",
    "    y_true = np.argmax(y_test_fold, axis = 0)\n",
    "    print(\"Report: \" + str(train_index))\n",
    "\n",
    "    print(classification_report(y_test_fold, y_estimate))\n",
    "    \n",
    "    \n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "      max(lst_accu_stratified)*100, '%')\n",
    "print('\\nMinimum Accuracy:',\n",
    "      min(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Accuracy:',\n",
    "      statistics.mean(lst_accu_stratified)*100, '%')\n",
    "print('\\nStandard Deviation is:', statistics.stdev(lst_accu_stratified))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will run a neural network model to see if it performs better or worse than the random forest. I chose a neural net here because of the large number of features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0UYxb45rMm1w",
    "outputId": "d7658ea4-3b19-4e80-c354-2339d9854652",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               28160     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 8)                 72        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 103,328\n",
      "Trainable params: 103,328\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, stratify = y)\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, dtype = 'int64')\n",
    "y_test = tf.keras.utils.to_categorical(y_test, dtype = 'int64')\n",
    "\n",
    "x_train_scaled = ct.fit_transform(x_train)\n",
    "x_test_scaled = ct.fit_transform(x_test)\n",
    "\n",
    "model.add(InputLayer(x_train_scaled.shape[1],))\n",
    "\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(8, activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3178/3178 [==============================] - 4s 1ms/step - loss: 0.2596 - categorical_accuracy: 0.8945\n",
      "Epoch 2/5\n",
      "3178/3178 [==============================] - 4s 1ms/step - loss: 0.2449 - categorical_accuracy: 0.9004\n",
      "Epoch 3/5\n",
      "3178/3178 [==============================] - 4s 1ms/step - loss: 0.2340 - categorical_accuracy: 0.9055\n",
      "Epoch 4/5\n",
      "3178/3178 [==============================] - 4s 1ms/step - loss: 0.2232 - categorical_accuracy: 0.9096\n",
      "Epoch 5/5\n",
      "3178/3178 [==============================] - 4s 1ms/step - loss: 0.2155 - categorical_accuracy: 0.9132\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.89      0.91     63552\n",
      "           2       0.91      0.94      0.93     84991\n",
      "           3       0.90      0.91      0.90     10726\n",
      "           4       0.87      0.74      0.80       824\n",
      "           5       0.81      0.65      0.72      2848\n",
      "           6       0.82      0.80      0.81      5210\n",
      "           7       0.91      0.92      0.92      6153\n",
      "\n",
      "    accuracy                           0.91    174304\n",
      "   macro avg       0.88      0.84      0.85    174304\n",
      "weighted avg       0.91      0.91      0.91    174304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = [\"categorical_accuracy\"])\n",
    "\n",
    "model.fit(x_train_scaled, y_train, epochs = EPOCHS, batch_size = BATCH_SIZE)\n",
    "y_estimate = model.predict(x_test_scaled)\n",
    "y_estimate = np.argmax(y_estimate, axis = 1)\n",
    "\n",
    "y_true = np.argmax(y_test, axis = 1)\n",
    "\n",
    "print(classification_report(y_true, y_estimate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XVAOpHmpOCO9",
    "outputId": "0c91178d-ee60-47d8-ebe5-7073abbf3147",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train shape:(464809, 54)\n",
      "y train shape:(464809,)\n",
      "Epoch 1/5\n",
      "3632/3632 [==============================] - 5s 1ms/step - loss: 0.0994 - sparse_categorical_accuracy: 0.9606\n",
      "Epoch 2/5\n",
      "3632/3632 [==============================] - 5s 1ms/step - loss: 0.0969 - sparse_categorical_accuracy: 0.9614\n",
      "Epoch 3/5\n",
      "3632/3632 [==============================] - 5s 1ms/step - loss: 0.0960 - sparse_categorical_accuracy: 0.9617\n",
      "Epoch 4/5\n",
      "3632/3632 [==============================] - 5s 1ms/step - loss: 0.0952 - sparse_categorical_accuracy: 0.9620A: 0s - loss: 0.0953 - sparse_categorical_accuracy: \n",
      "Epoch 5/5\n",
      "3632/3632 [==============================] - 5s 1ms/step - loss: 0.0952 - sparse_categorical_accuracy: 0.9623\n",
      "y estimate: (116203, 8)\n",
      "y estimate: (116203,)\n",
      "Report: [     0      1      2 ... 581009 581010 581011]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.96      0.96     42368\n",
      "           2       0.97      0.97      0.97     56660\n",
      "           3       0.96      0.96      0.96      7151\n",
      "           4       0.87      0.87      0.87       550\n",
      "           5       0.89      0.85      0.87      1899\n",
      "           6       0.94      0.92      0.93      3473\n",
      "           7       0.95      0.96      0.95      4102\n",
      "\n",
      "    accuracy                           0.96    116203\n",
      "   macro avg       0.93      0.93      0.93    116203\n",
      "weighted avg       0.96      0.96      0.96    116203\n",
      "\n",
      "x train shape:(464809, 54)\n",
      "y train shape:(464809,)\n",
      "Epoch 1/5\n",
      "3632/3632 [==============================] - 5s 1ms/step - loss: 0.0965 - sparse_categorical_accuracy: 0.9614A: 2\n",
      "Epoch 2/5\n",
      "3632/3632 [==============================] - 5s 1ms/step - loss: 0.0953 - sparse_categorical_accuracy: 0.9621A: 2s - loss: 0.0944 - - ETA: 0s - loss: 0.0953 - sparse_categorical_accuracy: 0\n",
      "Epoch 3/5\n",
      "3632/3632 [==============================] - 5s 1ms/step - loss: 0.0943 - sparse_categorical_accuracy: 0.9621\n",
      "Epoch 4/5\n",
      "3632/3632 [==============================] - 5s 1ms/step - loss: 0.0938 - sparse_categorical_accuracy: 0.9627\n",
      "Epoch 5/5\n",
      "3632/3632 [==============================] - 5s 1ms/step - loss: 0.0930 - sparse_categorical_accuracy: 0.9630A: 3s - loss: 0.0899 - sparse_categorical_accur\n",
      "y estimate: (116203, 8)\n",
      "y estimate: (116203,)\n",
      "Report: [     0      2      3 ... 581009 581010 581011]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.97      0.95      0.96     42368\n",
      "           2       0.96      0.98      0.97     56660\n",
      "           3       0.96      0.96      0.96      7151\n",
      "           4       0.84      0.90      0.87       550\n",
      "           5       0.90      0.84      0.87      1899\n",
      "           6       0.93      0.93      0.93      3473\n",
      "           7       0.97      0.96      0.96      4102\n",
      "\n",
      "    accuracy                           0.96    116203\n",
      "   macro avg       0.93      0.93      0.93    116203\n",
      "weighted avg       0.96      0.96      0.96    116203\n",
      "\n",
      "x train shape:(464810, 54)\n",
      "y train shape:(464810,)\n",
      "Epoch 1/5\n",
      "3632/3632 [==============================] - 5s 1ms/step - loss: 0.0950 - sparse_categorical_accuracy: 0.9619\n",
      "Epoch 2/5\n",
      "3632/3632 [==============================] - 5s 1ms/step - loss: 0.0934 - sparse_categorical_accuracy: 0.9629\n",
      "Epoch 3/5\n",
      "3632/3632 [==============================] - 5s 1ms/step - loss: 0.0926 - sparse_categorical_accuracy: 0.9631\n",
      "Epoch 4/5\n",
      "3632/3632 [==============================] - 5s 1ms/step - loss: 0.0917 - sparse_categorical_accuracy: 0.9634\n",
      "Epoch 5/5\n",
      "3632/3632 [==============================] - 5s 1ms/step - loss: 0.0912 - sparse_categorical_accuracy: 0.9636\n",
      "y estimate: (116202, 8)\n",
      "y estimate: (116202,)\n",
      "Report: [     1      2      3 ... 581008 581009 581011]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.96      0.96     42368\n",
      "           2       0.97      0.97      0.97     56660\n",
      "           3       0.97      0.95      0.96      7151\n",
      "           4       0.89      0.86      0.87       549\n",
      "           5       0.87      0.89      0.88      1899\n",
      "           6       0.91      0.95      0.93      3473\n",
      "           7       0.98      0.93      0.95      4102\n",
      "\n",
      "    accuracy                           0.96    116202\n",
      "   macro avg       0.93      0.93      0.93    116202\n",
      "weighted avg       0.96      0.96      0.96    116202\n",
      "\n",
      "x train shape:(464810, 54)\n",
      "y train shape:(464810,)\n",
      "Epoch 1/5\n",
      "3632/3632 [==============================] - 5s 1ms/step - loss: 0.0930 - sparse_categorical_accuracy: 0.9632\n",
      "Epoch 2/5\n",
      "3632/3632 [==============================] - 5s 1ms/step - loss: 0.0916 - sparse_categorical_accuracy: 0.9634\n",
      "Epoch 3/5\n",
      "3632/3632 [==============================] - 5s 1ms/step - loss: 0.0908 - sparse_categorical_accuracy: 0.9638\n",
      "Epoch 4/5\n",
      "3632/3632 [==============================] - 5s 1ms/step - loss: 0.0896 - sparse_categorical_accuracy: 0.9645\n",
      "Epoch 5/5\n",
      "3632/3632 [==============================] - 5s 1ms/step - loss: 0.0898 - sparse_categorical_accuracy: 0.9641\n",
      "y estimate: (116202, 8)\n",
      "y estimate: (116202,)\n",
      "Report: [     0      1      3 ... 581007 581008 581010]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.97      0.96     42368\n",
      "           2       0.97      0.96      0.97     56661\n",
      "           3       0.95      0.96      0.96      7150\n",
      "           4       0.84      0.92      0.88       549\n",
      "           5       0.86      0.90      0.88      1898\n",
      "           6       0.94      0.91      0.93      3474\n",
      "           7       0.98      0.93      0.95      4102\n",
      "\n",
      "    accuracy                           0.96    116202\n",
      "   macro avg       0.93      0.94      0.93    116202\n",
      "weighted avg       0.96      0.96      0.96    116202\n",
      "\n",
      "x train shape:(464810, 54)\n",
      "y train shape:(464810,)\n",
      "Epoch 1/5\n",
      "3632/3632 [==============================] - 5s 1ms/step - loss: 0.0912 - sparse_categorical_accuracy: 0.9638A: 0s - loss: 0.0911 - sparse_categorical\n",
      "Epoch 2/5\n",
      "3632/3632 [==============================] - 5s 1ms/step - loss: 0.0895 - sparse_categorical_accuracy: 0.9645\n",
      "Epoch 3/5\n",
      "3632/3632 [==============================] - 5s 1ms/step - loss: 0.0890 - sparse_categorical_accuracy: 0.9645\n",
      "Epoch 4/5\n",
      "3632/3632 [==============================] - 5s 1ms/step - loss: 0.0884 - sparse_categorical_accuracy: 0.9649\n",
      "Epoch 5/5\n",
      "3632/3632 [==============================] - 5s 1ms/step - loss: 0.0872 - sparse_categorical_accuracy: 0.9653\n",
      "y estimate: (116202, 8)\n",
      "y estimate: (116202,)\n",
      "Report: [     0      1      2 ... 581009 581010 581011]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.97      0.96     42368\n",
      "           2       0.97      0.96      0.97     56660\n",
      "           3       0.97      0.95      0.96      7151\n",
      "           4       0.89      0.83      0.86       549\n",
      "           5       0.91      0.85      0.88      1898\n",
      "           6       0.93      0.94      0.93      3474\n",
      "           7       0.99      0.90      0.94      4102\n",
      "\n",
      "    accuracy                           0.96    116202\n",
      "   macro avg       0.94      0.92      0.93    116202\n",
      "weighted avg       0.96      0.96      0.96    116202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = [\"sparse_categorical_accuracy\"])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "lst_accu_stratified = []\n",
    "  \n",
    "for train_index, test_index in skf.split(X_array, y):\n",
    "    x_train_fold, x_test_fold = X_array[train_index],X_array[test_index]\n",
    "    print('x train shape:' + str(x_train_fold.shape))\n",
    "    y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "    print('y train shape:' + str(y_train_fold.shape))\n",
    "    model.fit(ct.fit_transform(x_train_fold), y_train_fold, epochs = EPOCHS, batch_size = BATCH_SIZE)\n",
    "    y_estimate = model.predict(ct.transform(x_test_fold))\n",
    "    print('y estimate: ' + str(y_estimate.shape))\n",
    "    y_estimate = np.argmax(y_estimate, axis = 1)\n",
    "    print('y estimate: ' + str(y_estimate.shape))\n",
    "    y_true = np.argmax(y_test_fold, axis = 0)\n",
    "    print(\"Report: \" + str(train_index))\n",
    "\n",
    "    print(classification_report(y_test_fold, y_estimate))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "CoverType-classification.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "2c9237ed022b03eb7f9858fe1f6c20feed3f3c555f72bdcd7e20502bd51e372a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
